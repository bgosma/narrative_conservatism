{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\github\\\\narrative_conservatism\\\\code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############### import packages\n",
    "import os, requests, sys, re, pandas as pd, time\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from time import process_time\n",
    "\n",
    "##########################################################\n",
    "##################### parameter ##########################\n",
    "##########################################################\n",
    "obj_type = '8-K'\n",
    "period_start = 2005 # included\n",
    "period_end = 2007 # included\n",
    "\n",
    "############### Set working directory to parent directory\n",
    "os.getcwd()\n",
    "# os.chdir('F:\\\\github\\\\narrative_conservatism\\\\code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323896"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################### Access all fillings through SEC master index #################################\n",
    "####### indexes downloaded using python-edgar: https://github.com/edouardswiac/python-edgar #######\n",
    "#### open terminal, and run the following lines:\n",
    "#### cd F:\\github\\python-edgar-master (switch dir to where the run.py script is located)\n",
    "#### python run.py -y 1993 -d edgar_idx (downloading all quarterly master index from 1993 into folder edgar_idx)\n",
    "\n",
    "#### cd F:\\github\\python-edgar-master\\edgar-idx (switch dir to where the downloaded indexes are located)\n",
    "#### cat *.tsv > master.tsv (stitch all quarterly indexes into one master index)\n",
    "#### du -h master.tsv (inspect how large the master index file is)\n",
    "\n",
    "index_edgar = list()\n",
    "doc_url = list()\n",
    "\n",
    "# create an index of downloaded local quarterly master indexes\n",
    "for subdir, dirs, files in os.walk(\"F:\\\\github\\\\python-edgar-master\\\\edgar-idx\"):\n",
    "    for file in files:\n",
    "        file_year = int(file.split('-')[0])\n",
    "        if file_year >= period_start and file_year <= period_end:\n",
    "            index_edgar.append(os.path.join(subdir, file))\n",
    "\n",
    "# read each index file, select rows with matched file type, and store matched doc_links\n",
    "for filenameTSV in index_edgar:\n",
    "    tsv_read = pd.read_csv(filenameTSV, sep='|', header=None, encoding = \"utf-8\")\n",
    "    tsv_read.columns = ['1', '2', '3', '4', '5', '6']\n",
    "    \n",
    "    # select the rows with filetype equal to predefined type\n",
    "    tsv_type = tsv_read.loc[tsv_read['3'] == obj_type]\n",
    "    doc_link = tsv_type['6'].values.tolist()\n",
    "    doc_link = ['https://www.sec.gov/Archives/' + w for w in doc_link]\n",
    "    for doc in doc_link:\n",
    "        doc_url.append(doc)\n",
    "        \n",
    "len(doc_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #################### Access all fillings through SEC search engine ####################################\n",
    "# ################## NOT RECOMMENDED AT ALL #############################################################\n",
    "# cik = '0000051143'\n",
    "# obj_type = '8-K'\n",
    "# number of documents listed per page\n",
    "# count = '100'\n",
    "# # index of first document listed in the current page\n",
    "# start = '0'\n",
    "# # find filings prior to the date 2016y01m01d\n",
    "# dateb = ''\n",
    "\n",
    "# # Obtain url for intial search result page\n",
    "# base_url = \"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={}&type={}&dateb={}&start={}&count={}\"\n",
    "# init_url = base_url.format(cik, obj_type, dateb, start, count)\n",
    "\n",
    "# # define a function that takes the input url and returns next search page url\n",
    "# def get_next_url(input_url):\n",
    "#     edgar_resp = requests.get(input_url)\n",
    "#     edgar_str = edgar_resp.text\n",
    "#     soup = BeautifulSoup(edgar_str, 'html.parser')\n",
    "\n",
    "#     div_tag = soup.find('div', style='margin-top: 5px; margin-bottom: 5px;')\n",
    "#     button = div_tag.find('td', style='text-align: right;')\n",
    "#     fbutton = button.find_all('input')[0]['value']\n",
    "#     if re.findall(r'Next', fbutton) == ['Next']:\n",
    "#         next_url = button.find_all('input')[0]['onclick'][:-1]\n",
    "#     elif len(button.find_all('input')) == 2:\n",
    "#         next_url = button.find_all('input')[1]['onclick'][:-1]\n",
    "#     else:\n",
    "#         next_url = 'NA'\n",
    "        \n",
    "#     next_url = next_url.replace('parent.location=\\'', 'https://www.sec.gov')\n",
    "#     return next_url\n",
    "\n",
    "# # create a search result page url list\n",
    "# search_url = [init_url]\n",
    "\n",
    "# while get_next_url(init_url) != 'NA':\n",
    "#     search_url.append(get_next_url(init_url))\n",
    "#     init_url = get_next_url(init_url)\n",
    "    \n",
    "# ############### Create a document link list of a given CIK and file type\n",
    "# doc_link = list()\n",
    "\n",
    "# for url in search_url:\n",
    "#     edgar_resp = requests.get(url)\n",
    "#     edgar_str = edgar_resp.text\n",
    "#     soup = BeautifulSoup(edgar_str, 'html.parser')\n",
    "#     table_tag = soup.find('table', class_='tableFile2')\n",
    "#     rows = table_tag.find_all('tr')\n",
    "\n",
    "#     for row in rows[1:]:\n",
    "#         cells = row.find_all('td')\n",
    "#         doc_link.append('https://www.sec.gov' + cells[1].a['href'])\n",
    "        \n",
    "# len(doc_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 323896/323896 [26:33:32<00:00,  3.39it/s]\n"
     ]
    }
   ],
   "source": [
    "############### Extract file identification info from doc_url\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36'}\n",
    "\n",
    "accnum = list()\n",
    "fd = list()\n",
    "rp = list()\n",
    "name = list()\n",
    "cik = list()\n",
    "sic = list()\n",
    "file_type = list()\n",
    "fye = list()\n",
    "state = list()\n",
    "bazip = list()\n",
    "item8k = list()\n",
    "web_url = list()\n",
    "\n",
    "for doc in tqdm(doc_url):\n",
    "    doc_resp = requests.get(doc, headers=headers)\n",
    "    doc_str = doc_resp.text\n",
    "    soup = BeautifulSoup(doc_str, 'html.parser')\n",
    "    \n",
    "    # Save the SEC accession number (accnum)\n",
    "    try:\n",
    "        div_tag = soup.find('div', id='formHeader')\n",
    "        secnum = div_tag.find('div', id='secNum')\n",
    "        a = secnum.get_text().split()[3]\n",
    "        accnum.append(a)\n",
    "    except:\n",
    "        accnum.append('NA')\n",
    "        pass\n",
    "\n",
    "    # Save the Filing Date and Reporting Period\n",
    "    try:\n",
    "        div_tag = soup.find('div', class_='formContent')\n",
    "        dates = div_tag.find_all('div', class_='info')\n",
    "        # Filing Date\n",
    "        a = dates[0].get_text()\n",
    "        fd.append(a)\n",
    "    except:\n",
    "        fd.append('NA')\n",
    "        pass\n",
    "    \n",
    "        # Reporting Period\n",
    "    try:\n",
    "        b = dates[3].get_text()\n",
    "        rp.append(b)\n",
    "    except:\n",
    "        rp.append('NA')\n",
    "        pass\n",
    "    \n",
    "    # For 8K files, Save item info\n",
    "    try:\n",
    "        if obj_type == '8-K':\n",
    "            c = dates[4].get_text()\n",
    "            clist = re.findall(r'\\d.\\d\\d', c)\n",
    "            if clist != []:\n",
    "                c = ', '.join(clist)\n",
    "                item8k.append(c)\n",
    "            else:\n",
    "                clist = re.findall(r'\\d+', c)\n",
    "                c = ', '.join(clist)\n",
    "                item8k.append(c)\n",
    "        else :\n",
    "            c = 'NA'\n",
    "            item8k.append(c)\n",
    "    except:\n",
    "        item8k.append('NA')\n",
    "        pass\n",
    "\n",
    "        # Save the Company name and CIK\n",
    "    try:\n",
    "        div_tag = soup.find('div', class_='companyInfo')\n",
    "        comname = div_tag.find('span', class_='companyName')\n",
    "        # Company Name\n",
    "        a = comname.get_text().split(\"\\n\")[0].replace(' (Filer)', '')\n",
    "        name.append(a)\n",
    "    except:\n",
    "        name.append('NA')\n",
    "        pass\n",
    "    \n",
    "        # CIK\n",
    "    try:\n",
    "        b = comname.get_text().split(\"\\n\")[1].replace('CIK: ', '').replace(' (see all company filings)', '')\n",
    "        cik.append(b)\n",
    "    except:\n",
    "        cik.append('NA')\n",
    "        pass\n",
    "\n",
    "        # Save Business Address ZIP \n",
    "    try:\n",
    "        div_tag = soup.find_all('div', class_='mailer')[1].find_all('span', class_='mailerAddress')[1]\n",
    "        ba = div_tag.get_text()\n",
    "        alist = re.findall(r'\\d\\d\\d\\d\\d', ba)\n",
    "        if alist == []:\n",
    "            div_tag = soup.find_all('div', class_='mailer')[1].find_all('span', class_='mailerAddress')[2]\n",
    "            ba = div_tag.get_text()\n",
    "            alist = re.findall(r'\\d\\d\\d\\d\\d', ba)\n",
    "        a = ', '.join(alist)\n",
    "        bazip.append(a)\n",
    "    except:\n",
    "        bazip.append('NA')\n",
    "        pass\n",
    "\n",
    "        # Save SIC, File Type, Fiscal Year End and State of Incorporation\n",
    "    try:\n",
    "        div_tag = soup.find('div', class_='companyInfo')\n",
    "        filinginfo = div_tag.find('p', class_='identInfo')\n",
    "        # SIC\n",
    "        a = filinginfo.get_text().split(\"|\")[5].split(\"SIC\")[1].split()[1]\n",
    "        sic.append(a)\n",
    "    except:\n",
    "        sic.append('NA')\n",
    "        pass\n",
    "    \n",
    "    # File Type\n",
    "    b = obj_type\n",
    "    file_type.append(b)\n",
    "        \n",
    "        # Fiscal Year End\n",
    "    try:\n",
    "        c = filinginfo.get_text().split(\"|\")[2].split(\"Type\")[0].split(\":\")[1]\n",
    "        fye.append(c)\n",
    "    except:\n",
    "        fye.append('NA')\n",
    "        pass\n",
    "    \n",
    "        # State\n",
    "    try:\n",
    "        d = filinginfo.get_text().split(\"|\")[1].split(\":\")[1]\n",
    "        state.append(d)\n",
    "    except:\n",
    "        state.append('NA')\n",
    "        pass\n",
    "\n",
    "    # Save the HTML/TXT website urls from doc_url to raw data folder\n",
    "    try:\n",
    "        table_tag = soup.find('table', class_='tableFile', summary='Document Format Files')\n",
    "        rows = table_tag.find_all('tr')\n",
    "        cell_html = rows[1].find_all('td')\n",
    "        html = cell_html[2].a['href'].replace('ix?doc=/', '')\n",
    "        cell_txt = rows[-1].find_all('td')\n",
    "        txt = cell_txt[2].a['href']\n",
    "\n",
    "        if html.endswith(\"htm\") or html.endswith(\"txt\"):\n",
    "            web_url.append('https://www.sec.gov' + html)\n",
    "        else:\n",
    "            web_url.append('https://www.sec.gov' + txt)\n",
    "    \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accnum</th>\n",
       "      <th>file_type</th>\n",
       "      <th>cik</th>\n",
       "      <th>name</th>\n",
       "      <th>sic</th>\n",
       "      <th>fd</th>\n",
       "      <th>rp</th>\n",
       "      <th>fye</th>\n",
       "      <th>item8k</th>\n",
       "      <th>bazip</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0001104659-05-006777</td>\n",
       "      <td>8-K</td>\n",
       "      <td>0001000015</td>\n",
       "      <td>META GROUP INC</td>\n",
       "      <td>8700</td>\n",
       "      <td>2005-02-15</td>\n",
       "      <td>2005-02-15</td>\n",
       "      <td>1231</td>\n",
       "      <td>2.02, 9.01</td>\n",
       "      <td>06912</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0000950123-05-003812</td>\n",
       "      <td>8-K</td>\n",
       "      <td>0001000015</td>\n",
       "      <td>META GROUP INC</td>\n",
       "      <td>8700</td>\n",
       "      <td>2005-03-30</td>\n",
       "      <td>2005-03-28</td>\n",
       "      <td>1231</td>\n",
       "      <td>1.01, 9.01</td>\n",
       "      <td>06912</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0001000045-05-000001</td>\n",
       "      <td>8-K</td>\n",
       "      <td>0001000045</td>\n",
       "      <td>NICHOLAS FINANCIAL INC</td>\n",
       "      <td>6153</td>\n",
       "      <td>2005-01-27</td>\n",
       "      <td>2005-01-27</td>\n",
       "      <td>0331</td>\n",
       "      <td>2.02, 9.01</td>\n",
       "      <td>33759</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0001000045-05-000002</td>\n",
       "      <td>8-K</td>\n",
       "      <td>0001000045</td>\n",
       "      <td>NICHOLAS FINANCIAL INC</td>\n",
       "      <td>6153</td>\n",
       "      <td>2005-02-22</td>\n",
       "      <td>2005-02-22</td>\n",
       "      <td>0331</td>\n",
       "      <td>8.01, 9.01</td>\n",
       "      <td>33759</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001085037-05-000114</td>\n",
       "      <td>8-K</td>\n",
       "      <td>0001000157</td>\n",
       "      <td>DATAWAVE SYSTEMS INC</td>\n",
       "      <td>4812</td>\n",
       "      <td>2005-01-27</td>\n",
       "      <td>2005-01-26</td>\n",
       "      <td>0331</td>\n",
       "      <td>1.01, 3.02, 9.01</td>\n",
       "      <td>NA</td>\n",
       "      <td>B0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>323891</td>\n",
       "      <td>0001299933-07-007262</td>\n",
       "      <td>8-K</td>\n",
       "      <td>0000099780</td>\n",
       "      <td>TRINITY INDUSTRIES INC</td>\n",
       "      <td>3743</td>\n",
       "      <td>2007-12-18</td>\n",
       "      <td>2007-12-12</td>\n",
       "      <td>1231</td>\n",
       "      <td>5.02, 5.03, 8.01, 9.01</td>\n",
       "      <td>75207</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>323892</td>\n",
       "      <td>0001193125-07-216645</td>\n",
       "      <td>8-K</td>\n",
       "      <td>0000009984</td>\n",
       "      <td>BARNES GROUP INC</td>\n",
       "      <td>3490</td>\n",
       "      <td>2007-10-11</td>\n",
       "      <td>2007-10-05</td>\n",
       "      <td>1231</td>\n",
       "      <td>2.02, 5.02, 7.01, 9.01</td>\n",
       "      <td>06010</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>323893</td>\n",
       "      <td>0001157523-07-010634</td>\n",
       "      <td>8-K</td>\n",
       "      <td>0000009984</td>\n",
       "      <td>BARNES GROUP INC</td>\n",
       "      <td>3490</td>\n",
       "      <td>2007-11-02</td>\n",
       "      <td>2007-11-01</td>\n",
       "      <td>1231</td>\n",
       "      <td>2.02, 9.01</td>\n",
       "      <td>06010</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>323894</td>\n",
       "      <td>0001193125-07-251252</td>\n",
       "      <td>8-K</td>\n",
       "      <td>0000009984</td>\n",
       "      <td>BARNES GROUP INC</td>\n",
       "      <td>3490</td>\n",
       "      <td>2007-11-20</td>\n",
       "      <td>2007-11-15</td>\n",
       "      <td>1231</td>\n",
       "      <td>2.05</td>\n",
       "      <td>06010</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>323895</td>\n",
       "      <td>0001193125-07-268744</td>\n",
       "      <td>8-K</td>\n",
       "      <td>0000009984</td>\n",
       "      <td>BARNES GROUP INC</td>\n",
       "      <td>3490</td>\n",
       "      <td>2007-12-20</td>\n",
       "      <td>2007-12-20</td>\n",
       "      <td>1231</td>\n",
       "      <td>8.01, 9.01</td>\n",
       "      <td>06010</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323896 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      accnum file_type          cik                    name  \\\n",
       "0       0001104659-05-006777       8-K   0001000015          META GROUP INC   \n",
       "1       0000950123-05-003812       8-K   0001000015          META GROUP INC   \n",
       "2       0001000045-05-000001       8-K   0001000045  NICHOLAS FINANCIAL INC   \n",
       "3       0001000045-05-000002       8-K   0001000045  NICHOLAS FINANCIAL INC   \n",
       "4       0001085037-05-000114       8-K   0001000157    DATAWAVE SYSTEMS INC   \n",
       "...                      ...       ...          ...                     ...   \n",
       "323891  0001299933-07-007262       8-K   0000099780  TRINITY INDUSTRIES INC   \n",
       "323892  0001193125-07-216645       8-K   0000009984        BARNES GROUP INC   \n",
       "323893  0001157523-07-010634       8-K   0000009984        BARNES GROUP INC   \n",
       "323894  0001193125-07-251252       8-K   0000009984        BARNES GROUP INC   \n",
       "323895  0001193125-07-268744       8-K   0000009984        BARNES GROUP INC   \n",
       "\n",
       "         sic          fd          rp    fye                  item8k  bazip  \\\n",
       "0       8700  2005-02-15  2005-02-15   1231              2.02, 9.01  06912   \n",
       "1       8700  2005-03-30  2005-03-28   1231              1.01, 9.01  06912   \n",
       "2       6153  2005-01-27  2005-01-27   0331              2.02, 9.01  33759   \n",
       "3       6153  2005-02-22  2005-02-22   0331              8.01, 9.01  33759   \n",
       "4       4812  2005-01-27  2005-01-26   0331        1.01, 3.02, 9.01     NA   \n",
       "...      ...         ...         ...    ...                     ...    ...   \n",
       "323891  3743  2007-12-18  2007-12-12   1231  5.02, 5.03, 8.01, 9.01  75207   \n",
       "323892  3490  2007-10-11  2007-10-05   1231  2.02, 5.02, 7.01, 9.01  06010   \n",
       "323893  3490  2007-11-02  2007-11-01   1231              2.02, 9.01  06010   \n",
       "323894  3490  2007-11-20  2007-11-15   1231                    2.05  06010   \n",
       "323895  3490  2007-12-20  2007-12-20   1231              8.01, 9.01  06010   \n",
       "\n",
       "       state  \n",
       "0        DE   \n",
       "1        DE   \n",
       "2        FL   \n",
       "3        FL   \n",
       "4        B0   \n",
       "...      ...  \n",
       "323891   DE   \n",
       "323892   DE   \n",
       "323893   DE   \n",
       "323894   DE   \n",
       "323895   DE   \n",
       "\n",
       "[323896 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############### Save web_url to local index\n",
    "path_web_url_index = '..\\\\filings\\\\web_url_index_'+ obj_type + '_' + str(period_start) + '-' + str(period_end) + '.txt'\n",
    "with open(path_web_url_index, \"w\") as f:\n",
    "    for s in web_url:\n",
    "        f.write(s +\"\\n\")\n",
    "        \n",
    "############### Scraping adjustments for some exceptional data\n",
    "for index, w in enumerate(state):\n",
    "    if re.findall(r'\\DType', w) != []:\n",
    "        state[index] = w.split('Type')[0]\n",
    "    if re.findall(r'\\dType', w) != []:\n",
    "        fye[index] = w.split('Type')[0]\n",
    "        state[index] = 'NA'\n",
    "    if w == ' 34 ':\n",
    "        state[index] = 'NA'\n",
    "        \n",
    "for index, date in enumerate(fye):\n",
    "    if re.findall(r'[A-Z]', date) != []:\n",
    "        state[index] = date\n",
    "        fye[index] = 'NA'\n",
    "    if re.findall('-', date) != []:\n",
    "        fye[index] = 'NA'\n",
    "    if date == ' 34 ':\n",
    "        fye[index] = 'NA'\n",
    "\n",
    "for index, zipcode in enumerate(bazip):\n",
    "    if zipcode == '00000' or zipcode == '':\n",
    "        bazip[index] = 'NA'\n",
    "        \n",
    "############### Create Data Frame\n",
    "d = {'accnum': accnum, 'file_type': file_type, 'cik': cik, 'name': name, 'sic': sic, 'fd': fd, 'rp': rp, 'fye': fye, 'item8k': item8k, \\\n",
    "     'bazip': bazip, 'state': state}\n",
    "id_data = pd.DataFrame(data=d)\n",
    "id_data.to_csv('..\\\\filings\\\\id_data_' + obj_type + '_' + str(period_start) + '-' + str(period_end) +'.csv', index=False)\n",
    "\n",
    "id_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############### Download HTML into TXT files (NOT RECOMMANDED DUE TO LARGE FILE SIZE)\n",
    "# for link in web_url:\n",
    "#     if os.path.exists('..\\\\filings\\\\raw\\\\'+str(accnum[web_url.index(link)])+'.txt') == False:\n",
    "#         urllib.request.urlretrieve(link, '..\\\\filings\\\\raw\\\\'+str(accnum[web_url.index(link)])+'.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
