{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\github\\\\narrative_conservatism\\\\code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############### Set working directory to parent directory\n",
    "import os, requests, re\n",
    "from bs4 import BeautifulSoup\n",
    "os.getcwd()\n",
    "# os.chdir('F:\\\\github\\\\narrative_conservatism\\\\code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Create online input html file index and output dir\n",
    "web_url = list()\n",
    "accnum = list()\n",
    "\n",
    "with open(\"..\\\\filings\\\\web_url_index.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        web_url.append(line)\n",
    "        \n",
    "with open(\"..\\\\filings\\\\accnum_index.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.replace('\\n', '')\n",
    "        accnum.append(line)\n",
    "        \n",
    "output_dir = [\"..\\\\filings\\\\processed\\\\\" + num + '.txt' for num in accnum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# 1. Read online input html\n",
    "############# 2. Process txt\n",
    "# 1) delete i) nondisplay section and ii) tables that contains more than 4 numbers\n",
    "################ 2) identify the sections? item 2 (10-Q); item 7 (10-K); 8-K specific files (exhibition)\n",
    "# 3) delete all HTML tags\n",
    "############# 3. Save to processed txt files\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36'}\n",
    "\n",
    "def number_digits(inputString):\n",
    "    return len(re.findall(r'\\s?\\d+\\W?\\d+\\s?', inputString))\n",
    "\n",
    "for doc in web_url:\n",
    "    # 1.\n",
    "    doc_resp = requests.get(doc, headers=headers)\n",
    "    doc_str = doc_resp.text\n",
    "    soup = BeautifulSoup(doc_str, 'html.parser')\n",
    "    \n",
    "    # 2.1).i): delete nondisplay section\n",
    "    nondisplay = soup.find('div', style=\"display:none;\") or soup.find('div', style=\"display:none\")\n",
    "    if nondisplay is not None:\n",
    "        _ = nondisplay.extract()\n",
    "            \n",
    "    # 2.1).ii): delete tables that contains more than 4 numbers\n",
    "    table_tag = soup.find_all('table')\n",
    "    for tab in table_tag:\n",
    "        if number_digits(tab.get_text()) > 4:\n",
    "            _ = tab.extract()\n",
    "                \n",
    "    # 2.3): delete html tags\n",
    "    text_content = soup.get_text()\n",
    "    # for line in text_content:\n",
    "        # line = line.strip()\n",
    "        \n",
    "    # 3.\n",
    "    text_file = open(output_dir[web_url.index(doc)], \"w\", encoding = \"utf-8\")\n",
    "    n = text_file.write(text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############# Create local raw/processed txt file index\n",
    "# index_input = list()\n",
    "# for subdir, dirs, files in os.walk(\"..\\\\filings\\\\raw\"):\n",
    "#     for file in files:\n",
    "#         index_input.append(os.path.join(subdir, file))\n",
    "        \n",
    "# index_output = [w.replace('raw', 'processed') for w in index_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############# 1. Read downloaded raw txt files\n",
    "# ############# 2. Process txt\n",
    "# # 1) delete i) nondisplay section and ii) tables that contains more than 4 numbers\n",
    "# ################ 2) identify the sections? item 2 (10-Q); item 7 (10-K); 8-K specific files (exhibition)\n",
    "# # 3) delete all HTML tags\n",
    "# ############# 3. Save to processed txt files\n",
    "\n",
    "# def number_digits(inputString):\n",
    "#     return len(re.findall(r'\\s?\\d+\\W?\\d+\\s?', inputString))\n",
    "\n",
    "# for file in index_input:\n",
    "#     with open(file) as f:\n",
    "#         # 1.\n",
    "#         soup = BeautifulSoup(f.read())\n",
    "        \n",
    "#         # 2.1).i): delete nondisplay section\n",
    "#         nondisplay = soup.find('div', style=\"display:none;\") or soup.find('div', style=\"display:none\")\n",
    "#         if nondisplay is not None:\n",
    "#             _ = nondisplay.extract()\n",
    "            \n",
    "#         # 2.1).ii): delete tables that contains more than 4 numbers\n",
    "#         table_tag = soup.find_all('table')\n",
    "#         for tab in table_tag:\n",
    "#             if number_digits(tab.get_text()) > 4:\n",
    "#                 _ = tab.extract()\n",
    "                \n",
    "#         # 2.3): delete html tags\n",
    "#         text_content = soup.get_text()\n",
    "        \n",
    "#         # 3.\n",
    "#         text_file = open(index_output[index_input.index(file)], \"w\", encoding = \"utf-8\")\n",
    "#         n = text_file.write(text_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
