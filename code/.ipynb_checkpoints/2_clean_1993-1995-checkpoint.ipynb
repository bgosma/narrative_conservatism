{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\github\\\\narrative_conservatism\\\\code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############### import packages\n",
    "import os, requests, re, time, pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from time import process_time\n",
    "\n",
    "##########################################################\n",
    "##################### parameter ##########################\n",
    "##########################################################\n",
    "obj_type = '8-K'\n",
    "period_start = 1993 # included\n",
    "period_end = 1995 # included\n",
    "output_folder_dir = \"H:\\\\data\\\\edgar\\\\processed\\\\\" + obj_type + '\\\\' + str(period_start) + '-' + str(period_end)\n",
    "\n",
    "############### Set working directory to parent directory\n",
    "os.getcwd()\n",
    "# os.chdir('F:\\\\github\\\\narrative_conservatism\\\\code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9960"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# Create 1. online input html file index and 2. local output dir index\n",
    "web_url = list()\n",
    "\n",
    "# 1. online input html file index\n",
    "path_web_url_index = '..\\\\filings\\\\web_url_index_'+ obj_type + '_' + str(period_start) + '-' + str(period_end) + '.txt'\n",
    "with open(path_web_url_index, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.replace('\\n', '')\n",
    "        web_url.append(line)\n",
    "\n",
    "# 2. local output dir index\n",
    "path_id_data = '..\\\\filings\\\\id_data_' + obj_type + '_' + str(period_start) + '-' + str(period_end) +'.csv'\n",
    "accnum = pd.read_csv(path_id_data, usecols=['accnum'], encoding = \"utf-8\").values.tolist()\n",
    "        \n",
    "if not os.path.exists(output_folder_dir):\n",
    "    os.mkdir(output_folder_dir)\n",
    "    \n",
    "output_dir = [\"H:\\\\data\\\\edgar\\\\processed\\\\\" + obj_type + '\\\\' + str(period_start) + '-' + str(period_end) + \\\n",
    "              '\\\\' + str(num) + '.txt' for num in accnum]\n",
    "output_dir = [w.replace('[\\'','').replace('\\']','') for w in output_dir]\n",
    "\n",
    "len(web_url)\n",
    "\n",
    "# web_url[:10]\n",
    "# output_dir[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████                                                                    | 1289/9960 [07:23<52:56,  2.73it/s]"
     ]
    }
   ],
   "source": [
    "############# 1. Read online input html\n",
    "############# 2. Process txt\n",
    "# 1) delete i) nondisplay section and ii) tables that contains more than 4 numbers\n",
    "################ 2) identify the sections? item 2 (10-Q); item 7 (10-K); 8-K specific files (exhibition)\n",
    "# 3) delete all HTML tags\n",
    "############# 3. Save to processed txt files\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36'}\n",
    "\n",
    "############# Define a function to count the number of numerical occurrence in a string\n",
    "def number_digits(inputString):\n",
    "    return len(re.findall(r'\\s?\\d+\\W?\\d+\\s?', inputString))\n",
    "\n",
    "# t1_start = process_time()\n",
    "t1_start = time.time()\n",
    "\n",
    "for doc in tqdm(web_url):\n",
    "    # 1.\n",
    "    doc_resp = requests.get(doc, headers=headers)\n",
    "    doc_str = doc_resp.text\n",
    "    soup = BeautifulSoup(doc_str, 'html.parser')\n",
    "    \n",
    "    # 2.1).i): delete nondisplay section\n",
    "    nondisplay = soup.find('div', style=\"display:none;\") or soup.find('div', style=\"display:none\")\n",
    "    if nondisplay is not None:\n",
    "        _ = nondisplay.extract()\n",
    "            \n",
    "    # 2.1).ii): delete tables that contains more than 4 numbers\n",
    "    table_tag = soup.find_all('table')\n",
    "    for tab in table_tag:\n",
    "        if number_digits(tab.get_text()) > 4:\n",
    "            _ = tab.extract()\n",
    "                \n",
    "    # 2.3): delete html tags\n",
    "    text_content = soup.get_text()\n",
    "    # for line in text_content:\n",
    "        # line = line.strip()\n",
    "        \n",
    "    # 3.\n",
    "    with open(output_dir[web_url.index(doc)], \"w\", encoding = \"utf-8\") as f:\n",
    "        f.write(text_content)\n",
    "\n",
    "# t1_end = process_time()\n",
    "t1_end = time.time()\n",
    "print(\"Elapsed time during the whole program in seconds:\", t1_end - t1_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
