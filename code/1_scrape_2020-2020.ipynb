{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\github\\\\narrative_conservatism\\\\code'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############### import packages\n",
    "import os, requests, sys, re, pandas as pd, time\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from time import process_time\n",
    "\n",
    "##########################################################\n",
    "##################### parameter ##########################\n",
    "##########################################################\n",
    "obj_type = '10-Q'\n",
    "period_start = 2020 # included\n",
    "period_end = 2020 # included\n",
    "\n",
    "############### Set working directory to parent directory\n",
    "os.getcwd()\n",
    "# os.chdir('F:\\\\github\\\\narrative_conservatism\\\\code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1054"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################### Access all fillings through SEC master index #################################\n",
    "####### indexes downloaded using python-edgar: https://github.com/edouardswiac/python-edgar #######\n",
    "#### open terminal, and run the following lines:\n",
    "#### cd F:\\github\\python-edgar-master (switch dir to where the run.py script is located)\n",
    "#### python run.py -y 1993 -d edgar_idx (downloading all quarterly master index from 1993 into folder edgar_idx)\n",
    "\n",
    "#### cd F:\\github\\python-edgar-master\\edgar-idx (switch dir to where the downloaded indexes are located)\n",
    "#### cat *.tsv > master.tsv (stitch all quarterly indexes into one master index)\n",
    "#### du -h master.tsv (inspect how large the master index file is)\n",
    "\n",
    "index_edgar = list()\n",
    "doc_url = list()\n",
    "\n",
    "# create an index of downloaded local quarterly master indexes\n",
    "for subdir, dirs, files in os.walk(\"F:\\\\github\\\\python-edgar-master\\\\edgar-idx\"):\n",
    "    for file in files:\n",
    "        file_year = int(file.split('-')[0])\n",
    "        if file_year >= period_start and file_year <= period_end:\n",
    "            index_edgar.append(os.path.join(subdir, file))\n",
    "\n",
    "# read each index file, select rows with matched file type, and store matched doc_links\n",
    "for filenameTSV in index_edgar:\n",
    "    tsv_read = pd.read_csv(filenameTSV, sep='|', header=None, encoding = \"utf-8\")\n",
    "    tsv_read.columns = ['1', '2', '3', '4', '5', '6']\n",
    "    \n",
    "    # select the rows with filetype equal to predefined type\n",
    "    tsv_type = tsv_read.loc[tsv_read['3'] == obj_type]\n",
    "    doc_link = tsv_type['6'].values.tolist()\n",
    "    doc_link = ['https://www.sec.gov/Archives/' + w for w in doc_link]\n",
    "    for doc in doc_link:\n",
    "        doc_url.append(doc)\n",
    "        \n",
    "len(doc_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #################### Access all fillings through SEC search engine ####################################\n",
    "# ################## NOT RECOMMENDED AT ALL #############################################################\n",
    "# cik = '0000051143'\n",
    "# obj_type = '8-K'\n",
    "# number of documents listed per page\n",
    "# count = '100'\n",
    "# # index of first document listed in the current page\n",
    "# start = '0'\n",
    "# # find filings prior to the date 2016y01m01d\n",
    "# dateb = ''\n",
    "\n",
    "# # Obtain url for intial search result page\n",
    "# base_url = \"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={}&type={}&dateb={}&start={}&count={}\"\n",
    "# init_url = base_url.format(cik, obj_type, dateb, start, count)\n",
    "\n",
    "# # define a function that takes the input url and returns next search page url\n",
    "# def get_next_url(input_url):\n",
    "#     edgar_resp = requests.get(input_url)\n",
    "#     edgar_str = edgar_resp.text\n",
    "#     soup = BeautifulSoup(edgar_str, 'html.parser')\n",
    "\n",
    "#     div_tag = soup.find('div', style='margin-top: 5px; margin-bottom: 5px;')\n",
    "#     button = div_tag.find('td', style='text-align: right;')\n",
    "#     fbutton = button.find_all('input')[0]['value']\n",
    "#     if re.findall(r'Next', fbutton) == ['Next']:\n",
    "#         next_url = button.find_all('input')[0]['onclick'][:-1]\n",
    "#     elif len(button.find_all('input')) == 2:\n",
    "#         next_url = button.find_all('input')[1]['onclick'][:-1]\n",
    "#     else:\n",
    "#         next_url = 'NA'\n",
    "        \n",
    "#     next_url = next_url.replace('parent.location=\\'', 'https://www.sec.gov')\n",
    "#     return next_url\n",
    "\n",
    "# # create a search result page url list\n",
    "# search_url = [init_url]\n",
    "\n",
    "# while get_next_url(init_url) != 'NA':\n",
    "#     search_url.append(get_next_url(init_url))\n",
    "#     init_url = get_next_url(init_url)\n",
    "    \n",
    "# ############### Create a document link list of a given CIK and file type\n",
    "# doc_link = list()\n",
    "\n",
    "# for url in search_url:\n",
    "#     edgar_resp = requests.get(url)\n",
    "#     edgar_str = edgar_resp.text\n",
    "#     soup = BeautifulSoup(edgar_str, 'html.parser')\n",
    "#     table_tag = soup.find('table', class_='tableFile2')\n",
    "#     rows = table_tag.find_all('tr')\n",
    "\n",
    "#     for row in rows[1:]:\n",
    "#         cells = row.find_all('td')\n",
    "#         doc_link.append('https://www.sec.gov' + cells[1].a['href'])\n",
    "        \n",
    "# len(doc_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1054/1054 [05:37<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time during the whole program in seconds: 337.50095224380493\n"
     ]
    }
   ],
   "source": [
    "############### Extract file identification info from doc_url\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36'}\n",
    "\n",
    "accnum = list()\n",
    "fd = list()\n",
    "rp = list()\n",
    "name = list()\n",
    "cik = list()\n",
    "sic = list()\n",
    "file_type = list()\n",
    "fye = list()\n",
    "state = list()\n",
    "bazip = list()\n",
    "item8k = list()\n",
    "web_url = list()\n",
    "\n",
    "# t1_start = process_time()\n",
    "t1_start = time.time()\n",
    "\n",
    "for doc in tqdm(doc_url):\n",
    "    doc_resp = requests.get(doc, headers=headers)\n",
    "    doc_str = doc_resp.text\n",
    "    soup = BeautifulSoup(doc_str, 'html.parser')\n",
    "    \n",
    "    # Save the SEC accession number (accnum)\n",
    "    try:\n",
    "        div_tag = soup.find('div', id='formHeader')\n",
    "        secnum = div_tag.find('div', id='secNum')\n",
    "        a = secnum.get_text().split()[3]\n",
    "        accnum.append(a)\n",
    "    except:\n",
    "        accnum.append('NA')\n",
    "        pass\n",
    "\n",
    "    # Save the Filing Date and Reporting Period\n",
    "    try:\n",
    "        div_tag = soup.find('div', class_='formContent')\n",
    "        dates = div_tag.find_all('div', class_='info')\n",
    "        # Filing Date\n",
    "        a = dates[0].get_text()\n",
    "        fd.append(a)\n",
    "    except:\n",
    "        fd.append('NA')\n",
    "        pass\n",
    "    \n",
    "        # Reporting Period\n",
    "    try:\n",
    "        b = dates[3].get_text()\n",
    "        rp.append(b)\n",
    "    except:\n",
    "        rp.append('NA')\n",
    "        pass\n",
    "    \n",
    "    # For 8K files, Save item info\n",
    "    if obj_type == '8-K':\n",
    "        c = dates[4].get_text()\n",
    "        clist = re.findall(r'\\d.\\d\\d', c)\n",
    "        if clist != []:\n",
    "            c = ', '.join(clist)\n",
    "            item8k.append(c)\n",
    "        else:\n",
    "            clist = re.findall(r'\\d', c)\n",
    "            c = ', '.join(clist)\n",
    "            item8k.append(c)\n",
    "    else :\n",
    "        c = 'NA'\n",
    "        item8k.append(c)\n",
    "\n",
    "        # Save the Company name and CIK\n",
    "    try:\n",
    "        div_tag = soup.find('div', class_='companyInfo')\n",
    "        comname = div_tag.find('span', class_='companyName')\n",
    "        # Company Name\n",
    "        a = comname.get_text().split(\"\\n\")[0].replace(' (Filer)', '')\n",
    "        name.append(a)\n",
    "    except:\n",
    "        name.append('NA')\n",
    "        pass\n",
    "    \n",
    "        # CIK\n",
    "    try:\n",
    "        b = comname.get_text().split(\"\\n\")[1].replace('CIK: ', '').replace(' (see all company filings)', '')\n",
    "        cik.append(b)\n",
    "    except:\n",
    "        cik.append('NA')\n",
    "        pass\n",
    "\n",
    "        # Save Business Address ZIP \n",
    "    try:\n",
    "        div_tag = soup.find_all('div', class_='mailer')[1].find_all('span', class_='mailerAddress')[1]\n",
    "        ba = div_tag.get_text()\n",
    "        alist = re.findall(r'\\d\\d\\d\\d\\d', ba)\n",
    "        if alist == []:\n",
    "            div_tag = soup.find_all('div', class_='mailer')[1].find_all('span', class_='mailerAddress')[2]\n",
    "            ba = div_tag.get_text()\n",
    "            alist = re.findall(r'\\d\\d\\d\\d\\d', ba)\n",
    "        a = ', '.join(alist)\n",
    "        bazip.append(a)\n",
    "    except:\n",
    "        bazip.append('NA')\n",
    "        pass\n",
    "\n",
    "        # Save SIC, File Type, Fiscal Year End and State of Incorporation\n",
    "    try:\n",
    "        div_tag = soup.find('div', class_='companyInfo')\n",
    "        filinginfo = div_tag.find('p', class_='identInfo')\n",
    "        # SIC\n",
    "        a = filinginfo.get_text().split(\"|\")[5].split(\"SIC\")[1].split()[1]\n",
    "        sic.append(a)\n",
    "    except:\n",
    "        sic.append('NA')\n",
    "        pass\n",
    "    \n",
    "    # File Type\n",
    "    b = obj_type\n",
    "    file_type.append(b)\n",
    "        \n",
    "        # Fiscal Year End\n",
    "    try:\n",
    "        c = filinginfo.get_text().split(\"|\")[2].split(\"Type\")[0].split(\":\")[1]\n",
    "        fye.append(c)\n",
    "    except:\n",
    "        fye.append('NA')\n",
    "        pass\n",
    "    \n",
    "        # State\n",
    "    try:\n",
    "        d = filinginfo.get_text().split(\"|\")[1].split(\":\")[1]\n",
    "        state.append(d)\n",
    "    except:\n",
    "        state.append('NA')\n",
    "        pass\n",
    "\n",
    "    # Save the HTML/TXT website urls from doc_url to raw data folder\n",
    "    table_tag = soup.find('table', class_='tableFile', summary='Document Format Files')\n",
    "    rows = table_tag.find_all('tr')\n",
    "    cell_html = rows[1].find_all('td')\n",
    "    html = cell_html[2].a['href'].replace('ix?doc=/', '')\n",
    "    cell_txt = rows[-1].find_all('td')\n",
    "    txt = cell_txt[2].a['href']\n",
    "\n",
    "    if html.endswith(\"htm\") or html.endswith(\"txt\"):\n",
    "        web_url.append('https://www.sec.gov' + html)\n",
    "    else:\n",
    "        web_url.append('https://www.sec.gov' + txt)\n",
    "\n",
    "# t1_end = process_time()\n",
    "t1_end = time.time()\n",
    "print(\"Elapsed time during the whole program in seconds:\", t1_end - t1_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accnum</th>\n",
       "      <th>file_type</th>\n",
       "      <th>cik</th>\n",
       "      <th>name</th>\n",
       "      <th>sic</th>\n",
       "      <th>fd</th>\n",
       "      <th>rp</th>\n",
       "      <th>fye</th>\n",
       "      <th>item8k</th>\n",
       "      <th>bazip</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0001564590-20-004703</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>0001000045</td>\n",
       "      <td>NICHOLAS FINANCIAL INC</td>\n",
       "      <td>6153</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0331</td>\n",
       "      <td>NA</td>\n",
       "      <td>33759</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0001564590-20-003634</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>0001001115</td>\n",
       "      <td>GEOSPACE TECHNOLOGIES CORP</td>\n",
       "      <td>3829</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0930</td>\n",
       "      <td>NA</td>\n",
       "      <td>77040</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0001104659-20-011857</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>0001001250</td>\n",
       "      <td>ESTEE LAUDER COMPANIES INC</td>\n",
       "      <td>2844</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0630</td>\n",
       "      <td>NA</td>\n",
       "      <td>10153</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0001437749-20-003273</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>0001001258</td>\n",
       "      <td>ASTA FUNDING INC</td>\n",
       "      <td>6153</td>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0930</td>\n",
       "      <td>NA</td>\n",
       "      <td>07632</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001564590-20-004740</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>0001001907</td>\n",
       "      <td>ASTROTECH Corp</td>\n",
       "      <td>3826</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0630</td>\n",
       "      <td>NA</td>\n",
       "      <td>78701</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1049</td>\n",
       "      <td>0001171843-20-000876</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>0000096699</td>\n",
       "      <td>TECHNICAL COMMUNICATIONS CORP</td>\n",
       "      <td>3663</td>\n",
       "      <td>2020-02-11</td>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>1003</td>\n",
       "      <td>NA</td>\n",
       "      <td>01742</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0001564590-20-004619</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>0000096793</td>\n",
       "      <td>SUNLINK HEALTH SYSTEMS INC</td>\n",
       "      <td>8062</td>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0630</td>\n",
       "      <td>NA</td>\n",
       "      <td>30339</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1051</td>\n",
       "      <td>0001185185-20-000178</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>0000096885</td>\n",
       "      <td>TEL INSTRUMENT ELECTRONICS CORP</td>\n",
       "      <td>3670</td>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0331</td>\n",
       "      <td>NA</td>\n",
       "      <td>07073</td>\n",
       "      <td>NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1052</td>\n",
       "      <td>0001213900-20-000888</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>0000098338</td>\n",
       "      <td>TSR INC</td>\n",
       "      <td>7371</td>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>0531</td>\n",
       "      <td>NA</td>\n",
       "      <td>11788</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1053</td>\n",
       "      <td>0001206774-20-000370</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>0000099302</td>\n",
       "      <td>TRANSCAT INC</td>\n",
       "      <td>3825</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>0328</td>\n",
       "      <td>NA</td>\n",
       "      <td>14624</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1054 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    accnum file_type          cik  \\\n",
       "0     0001564590-20-004703      10-Q   0001000045   \n",
       "1     0001564590-20-003634      10-Q   0001001115   \n",
       "2     0001104659-20-011857      10-Q   0001001250   \n",
       "3     0001437749-20-003273      10-Q   0001001258   \n",
       "4     0001564590-20-004740      10-Q   0001001907   \n",
       "...                    ...       ...          ...   \n",
       "1049  0001171843-20-000876      10-Q   0000096699   \n",
       "1050  0001564590-20-004619      10-Q   0000096793   \n",
       "1051  0001185185-20-000178      10-Q   0000096885   \n",
       "1052  0001213900-20-000888      10-Q   0000098338   \n",
       "1053  0001206774-20-000370      10-Q   0000099302   \n",
       "\n",
       "                                 name   sic          fd          rp    fye  \\\n",
       "0              NICHOLAS FINANCIAL INC  6153  2020-02-14  2019-12-31   0331   \n",
       "1          GEOSPACE TECHNOLOGIES CORP  3829  2020-02-06  2019-12-31   0930   \n",
       "2          ESTEE LAUDER COMPANIES INC  2844  2020-02-06  2019-12-31   0630   \n",
       "3                    ASTA FUNDING INC  6153  2020-02-21  2019-12-31   0930   \n",
       "4                      ASTROTECH Corp  3826  2020-02-14  2019-12-31   0630   \n",
       "...                               ...   ...         ...         ...    ...   \n",
       "1049    TECHNICAL COMMUNICATIONS CORP  3663  2020-02-11  2019-12-28   1003   \n",
       "1050       SUNLINK HEALTH SYSTEMS INC  8062  2020-02-13  2019-12-31   0630   \n",
       "1051  TEL INSTRUMENT ELECTRONICS CORP  3670  2020-02-13  2019-12-31   0331   \n",
       "1052                          TSR INC  7371  2020-01-13  2019-11-30   0531   \n",
       "1053                     TRANSCAT INC  3825  2020-02-05  2019-12-28   0328   \n",
       "\n",
       "     item8k  bazip state  \n",
       "0        NA  33759   FL   \n",
       "1        NA  77040   TX   \n",
       "2        NA  10153   DE   \n",
       "3        NA  07632   DE   \n",
       "4        NA  78701   DE   \n",
       "...     ...    ...   ...  \n",
       "1049     NA  01742   MA   \n",
       "1050     NA  30339   OH   \n",
       "1051     NA  07073   NJ   \n",
       "1052     NA  11788   DE   \n",
       "1053     NA  14624   OH   \n",
       "\n",
       "[1054 rows x 11 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############### Save web_url to local index\n",
    "path_web_url_index = '..\\\\filings\\\\web_url_index_'+ obj_type + '_' + str(period_start) + '-' + str(period_end) + '.txt'\n",
    "with open(path_web_url_index, \"w\") as f:\n",
    "    for s in web_url:\n",
    "        f.write(s +\"\\n\")\n",
    "\n",
    "############### Scraping adjustments for some exceptional data\n",
    "for w in state:\n",
    "    if re.findall(r'\\DType', w) != []:\n",
    "        state[state.index(w)] = w.split('Type')[0]\n",
    "    if re.findall(r'\\dType', w) != []:\n",
    "        fye[state.index(w)] = w.split('Type')[0]\n",
    "        state[state.index(w)] = 'NA'\n",
    "    if w == ' 34 ':\n",
    "        state[state.index(w)] = 'NA'\n",
    "        \n",
    "for date in fye:\n",
    "    if re.findall(r'[A-Z]', date) != []:\n",
    "        state[fye.index(date)] = date\n",
    "        fye[fye.index(date)] = 'NA'\n",
    "    if re.findall('-', date) != []:\n",
    "        fye[fye.index(date)] = 'NA'\n",
    "    if date == ' 34 ':\n",
    "        fye[fye.index(date)] = 'NA'\n",
    "\n",
    "for zipcode in bazip:\n",
    "    if zipcode == '00000' or zipcode == '':\n",
    "        bazip[bazip.index(zipcode)] = 'NA'\n",
    "        \n",
    "############### Create Data Frame\n",
    "d = {'accnum': accnum, 'file_type': file_type, 'cik': cik, 'name': name, 'sic': sic, 'fd': fd, 'rp': rp, 'fye': fye, 'item8k': item8k, \\\n",
    "     'bazip': bazip, 'state': state}\n",
    "id_data = pd.DataFrame(data=d)\n",
    "id_data.to_csv('..\\\\filings\\\\id_data_' + obj_type + '_' + str(period_start) + '-' + str(period_end) +'.csv', index=False)\n",
    "\n",
    "id_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############### Download HTML into TXT files (NOT RECOMMANDED DUE TO LARGE FILE SIZE)\n",
    "# for link in web_url:\n",
    "#     if os.path.exists('..\\\\filings\\\\raw\\\\'+str(accnum[web_url.index(link)])+'.txt') == False:\n",
    "#         urllib.request.urlretrieve(link, '..\\\\filings\\\\raw\\\\'+str(accnum[web_url.index(link)])+'.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
